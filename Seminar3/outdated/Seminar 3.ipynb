{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar 3 (Data embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this seminar is to play around with diffrent techniques for data visualization. We are going work on the well-known  [MNIST](http://yann.lecun.com/exdb/mnist/). The dataset consists of 60,000 grayscale images of hand-written digits of size 28 $ \\times $ 28. Thus, the dimensionality of the input space is **784**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we provide the code that fetches the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Fetch MNIST dataset and create a local copy.\n",
    "if os.path.exists('mnist.npz'):\n",
    "    with np.load('mnist.npz', 'r') as data:\n",
    "        X = data['X']\n",
    "        y = data['y']\n",
    "else:\n",
    "    mnist = fetch_mldata(\"MNIST original\")\n",
    "    X, y = mnist.data / 255.0, mnist.target\n",
    "    np.savez('mnist.npz', X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn to plot some random representatives from each of 10 (obviously) available classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preferably arrange images as a 10x10 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole dataset is somewhat large so we restrict ourselves to the random subset of 5,000 images (corresponding indices are held in ``train_indices``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train_samples = 5000\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[: n_train_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA, Multidimensional scaling (MDS) and Locally Linear Embedding (LLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to try three different dimensionality reduction techniques which may be helpful for the visualization of high-dimensional data. The first one should be familiar to you: it's **PCA** with 2 components. The other two are non-linear embedding approaches described in the lecture, namely, [MDS](http://en.wikipedia.org/wiki/Multidimensional_scaling) and [LLE](http://web.stanford.edu/class/ee378b/papers/roweis.pdf). Plot all three embeddings and check if they are good enough for the dataset.\n",
    "\n",
    "**NOTE:** MDS (default settings) may take some time (>10 min) to compute, so be patient. It's probably a good idea to leave the exploration of this method as a hometask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.manifold import MDS, LocallyLinearEmbedding\n",
    "\n",
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isomap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to explore the manifold of **2**'s using [Isomap](http://web.mit.edu/cocosci/Papers/sci_reprint.pdf). First, you need to compute the embedding of the corresponding subset of MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "indices_of_2 = np.arange(X.shape[0])[y == 2]\n",
    "np.random.shuffle(indices_of_2)\n",
    "train_indices_of_2 = indices_of_2[: n_train_samples]\n",
    "\n",
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After it is done we can track how an appearance of the digit changes along the line. One can take two most distant points as the endpoints of the interpolation segment. The following code should extract closest points to the line. Use **``scipy.spatial.KDTree``** for the fast nearest neighbour computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from scipy import linspace\n",
    "\n",
    "def find_representatives(kdtree, from_point, to_point, n_points):\n",
    "    # Given two 2D points this function should return a sequence of the dataset representatives (indices) that\n",
    "    # we encounter nearby as we go from from_point to to_point. This can be done by taking a set points on \n",
    "    # the segment and finding corresponding nearest neighbours in the dataset.\n",
    "    \n",
    "    # Your code goes here.\n",
    "    \n",
    "    return representatives\n",
    "\n",
    "n_points = 100\n",
    "\n",
    "# Your code starts here and shoudld end with:\n",
    "# representatives = find_representatives(kdtree, X_embedded[from_idx, :], X_embedded[to_idx, :], n_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a bunch of helper functions for interpolation visualization. Note the **`diplay_manifold_flythrough`** function. First two arguments are array of images and their coordinates on the 2D plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "\n",
    "VIDEO_TAG = \"\"\"<video controls>\n",
    " <source src=\"data:video/x-m4v;base64,{0}\" type=\"video/mp4\">\n",
    " Your browser does not support the video tag.\n",
    "</video>\"\"\"\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    if not hasattr(anim, '_encoded_video'):\n",
    "        with open('temp.mp4', 'wb') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264'], writer='ffmpeg')\n",
    "            video = open('temp.mp4', \"rb\").read()\n",
    "        anim._encoded_video = video.encode(\"base64\")\n",
    "    \n",
    "    return VIDEO_TAG.format(anim._encoded_video)\n",
    "\n",
    "def display_animation(anim):\n",
    "    plt.close(anim._fig)\n",
    "    return HTML(anim_to_html(anim))\n",
    "\n",
    "def diplay_manifold_flythrough(X, coords, fig, ax):\n",
    "    imagebox = OffsetImage(X[0].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "    annbox = AnnotationBbox(imagebox, coords[0])\n",
    "    ax.add_artist(annbox)\n",
    "\n",
    "    def init():\n",
    "        return imagebox, annbox\n",
    "\n",
    "    def animate(i):\n",
    "        imagebox.set_data(X[i].reshape(28, 28))\n",
    "        annbox.xyann = coords[i]\n",
    "\n",
    "        return imagebox, annbox\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=X.shape[0], interval=20, blit=True)\n",
    "\n",
    "    return display_animation(anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use **`diplay_manifold_flythrough`** to display the manifold fly-through over the scatter plot of the subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(frameon=False)\n",
    "plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "# Your code starts here and should end with:\n",
    "# diplay_manifold_flythrough(..., ..., fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally create an animation of the interpolation. Specifically, you should obtain an animation similar to the one presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls>\n",
       "<source src='./interpolation.mp4' type='video/mp4'>\n",
       "Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML at 0x7fa73f2f46d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"<video controls>\n",
    "<source src='./interpolation.mp4' type='video/mp4'>\n",
    "Your browser does not support the video tag.\n",
    "</video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_interpolation(X, steps, fig):\n",
    "    # NOTE: First argument corresponds to the sequence of images.\n",
    "    \n",
    "    n_images = X.shape[0]\n",
    "    \n",
    "    im = plt.imshow(X[0].reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "\n",
    "    def init():\n",
    "        return im,\n",
    "    \n",
    "    def animate(i):\n",
    "        # Your code goes here.\n",
    "        \n",
    "        im.set_array(img)\n",
    "        return im,\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=steps, interval=20, blit=True)\n",
    "\n",
    "    return display_animation(anim)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = plt.axes(frameon=False)\n",
    "plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "# Your code starts here and should end with:\n",
    "# display_interpolation(.., 500, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-Distributed Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to visualize the whole set of digits, a much better embedding technique is [t-SNE](http://lvdmaaten.github.io/tsne/). This method has been proven to generate high-quality visualizations in various scenarios and has become a standard de-facto in analyzing high-dimensional data (like activities of neurons in an Artificial Neural Network). We are going to use a slower version of the algorithm supplied in the ``scikit-learn`` (**``sklearn.manifold.TSNE``**). In practice, however, I'd suggest to use an approximate [Barnes-Hut t-SNE](http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf) which produces comparable results while working substantially faster.\n",
    "\n",
    "Your task here is similar to the ones in the previous section. The differeces are:\n",
    "* You should use all digits (a ``train_indices`` subset)\n",
    "* The fly-through should capture all classes. One way to achieve this would be to use picker capabilities of ``matplotlib`` ([demo](http://matplotlib.org/examples/event_handling/pick_event_demo.html)) in order to manually pick a sequence of keypoints on a scatter plot. Given a list of keypoints, it's easy to obtain intermediate representatives using the **``find_representatives``** function. The rest of the code should be almost identical to the Isomap-case. **Don't forget about the interpolation animation :)**\n",
    "\n",
    "**NOTE 1:** t-SNE is available in the latest version of ``scikit-learn``. There is a ``python`` package called ``tsne`` (``pip install tsne``) which implements Barnes-Hut t-SNE. Feel free to use that one.\n",
    "\n",
    "**NOTE 2:** It may be a good idea to apply PCA (with, for example, 50 components) to the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Your code goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
